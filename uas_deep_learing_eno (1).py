# -*- coding: utf-8 -*-
"""UAS DEEP LEARING ENO

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EhYD0zKCL7tzDQBgAE_icW9Xgb4Y_s2Z
"""

import pandas as pd
import numpy as np
import pickle
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, accuracy_score

# 1. Load Dataset
df = pd.read_csv('/content/drive/MyDrive/UTS pembelajran mendalam /water_potability.csv')

# Cek data
print(df.head())

# 2. DATA PREPARATION (PREPROCESSING)
# ==========================================================
# Mengisi nilai yang kosong dengan rata-rata (Mean Imputation)
# Solusi agar model tidak error karena data kosong
df.fillna(df.mean(), inplace=True)

# Memisahkan Fitur dan Target
X = df.drop('Potability', axis=1)
y = df['Potability']

# Scaling Data (MinMaxScaler) - Menyamakan rentang nilai agar model stabil
scaler = MinMaxScaler()
X_scaled = scaler.fit_transform(X)

# Split Data (80% Training, 20% Testing)
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42, stratify=y
)

print(f"\n‚úÖ Data Siap! Training: {len(X_train)}, Testing: {len(X_test)}")

# 3. Pengujian 3 Model (Random Forest, SVM (Support Vector Machine), dan K-Nearest Neighbors (KNN).)
models = {
    "Random Forest": RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42),
    "SVM (Support Vector Machine)": SVC(probability=True, kernel='rbf', random_state=42),
    "KNN (K-Nearest Neighbors)": KNeighborsClassifier(n_neighbors=9)
}

# Training dan Evaluasi
best_acc = 0
best_model = None
best_model_name = ""

for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)

    print(f"\n--- Model: {name} ---")
    print(f"Accuracy: {acc:.4f}")
    print(classification_report(y_test, y_pred))

    if acc > best_acc:
        best_acc = acc
        best_model = model
        best_model_name = name

# 4. SIMPAN MODEL TERBAIK UNTUK WEBSITE
# ==========================================================
print(f"\nüèÜ Model Terbaik: {best_model_name} dengan Akurasi {best_acc:.4f}")

# Simpan model dan scaler ke file .pkl
with open('model_air.pkl', 'wb') as f:
    pickle.dump(best_model, f)

with open('scaler_air.pkl', 'wb') as f:
    pickle.dump(scaler, f)

print("üíæ Model dan Scaler telah disimpan sebagai model_air.pkl dan scaler_air.pkl")

import os
import pandas as pd

# 5. CEK LOKASI FILE DATASET
# ==========================================================
def find_csv_path(filename):
    for root, dirs, files in os.walk('/content'): # Mencari di direktori Colab
        if filename in files:
            return os.path.join(root, filename)
    return None

FILE_NAME = 'water_potability.csv'
PATH_DATASET = find_csv_path(FILE_NAME)

if PATH_DATASET:
    df = pd.read_csv(PATH_DATASET)
    print(f"‚úÖ Dataset ditemukan di: {PATH_DATASET}")
    print(f"üìä Jumlah Data: {df.shape[0]} baris, {df.shape[1]} kolom")
    print(f"üìÇ Kolom yang tersedia: {list(df.columns)}")
else:
    print(f"‚ùå File {FILE_NAME} tidak ditemukan. Silakan upload ke Google Colab.")

# Melihat 5 data teratas
df.head()

import matplotlib.pyplot as plt
import numpy as np
from sklearn.model_selection import learning_curve
from sklearn.ensemble import RandomForestClassifier

# ==========================================================
## A. GRAFIK PERFORMA RANDOM FOREST (Learning Curve)
# Digunakan untuk mendeteksi Overfitting pada Random Forest
# ==========================================================

def plot_learning_curve(estimator, title, X, y):
    # n_jobs=-1 menggunakan semua prosesor agar training lebih cepat
    train_sizes, train_scores, val_scores = learning_curve(
        estimator, X, y, cv=5, n_jobs=-1,
        train_sizes=np.linspace(0.1, 1.0, 10),
        scoring='accuracy',
        random_state=42
    )

    # Menghitung rata-rata dan standar deviasi skor
    train_mean = np.mean(train_scores, axis=1)
    train_std = np.std(train_scores, axis=1)
    val_mean = np.mean(val_scores, axis=1)
    val_std = np.std(val_scores, axis=1)

    plt.figure(figsize=(10, 6))

    # Plot Training Score (Warna Merah)
    plt.plot(train_sizes, train_mean, 'o-', color="r", label="Training Score")
    plt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color="r")

    # Plot Validation Score (Warna Hijau)
    plt.plot(train_sizes, val_mean, 'o-', color="g", label="Validation Score (Cross-Validation)")
    plt.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, alpha=0.1, color="g")

    plt.title(f'Learning Curve: {title}', fontsize=14)
    plt.xlabel('Jumlah Data Training yang Digunakan', fontsize=12)
    plt.ylabel('Akurasi', fontsize=12)
    plt.legend(loc="best")
    plt.grid(True, linestyle='--', alpha=0.7)
    plt.show()

# Pastikan 'best_model_obj' adalah Random Forest dari proses sebelumnya
# Jika ingin mendefinisikan ulang secara manual:
# best_model_obj = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)
# best_model_name = "Random Forest"

plot_learning_curve(best_model, "Random Forest Classifier", X_train, y_train)

import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import confusion_matrix # Added this import

# ==========================================================
## B. CONFUSION MATRIX - RANDOM FOREST
# ==========================================================

# Nama model yang konsisten dengan dictionary hasil training Anda
name_rf = "Random Forest"

# Mengambil data CM khusus dari model Random Forest
# The 'results' dictionary was not defined, so directly calculate cm
cm = confusion_matrix(y_test, models[name_rf].predict(X_test))

plt.figure(figsize=(8, 6))

plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
plt.title(f'{name_rf}\nConfusion Matrix', fontsize=14)
plt.colorbar()

# Label khusus untuk Water Potability (0: Tidak Layak, 1: Layak)
tick_marks = np.arange(2)
plt.xticks(tick_marks, ['Not Potable (0)', 'Potable (1)'], rotation=45)
plt.yticks(tick_marks, ['Not Potable (0)', 'Potable (1)'])

plt.ylabel('Label Asli (True Label)', fontsize=12)
plt.xlabel('Label Prediksi (Predicted Label)', fontsize=12)

# Menambahkan teks angka di dalam kotak matrix
thresh = cm.max() / 2.
for i in range(cm.shape[0]):
    for j in range(cm.shape[1]):
        plt.text(j, i, format(cm[i, j], 'd'),
                 ha="center", va="center",
                 color="white" if cm[i, j] > thresh else "black",
                 fontsize=14)

plt.tight_layout()
plt.show()

import matplotlib.pyplot as plt
from sklearn.metrics import roc_curve, roc_auc_score # Added roc_auc_score

# ==========================================================
## C. KURVA ROC - RANDOM FOREST
# ==========================================================

# 1. Pastikan mengambil data probabilitas khusus model Random Forest
name_rf = "Random Forest"

# Mengambil probabilitas prediksi untuk kelas 1 (Potable)
# Kita asumsikan 'model_rf' atau 'models[name_rf]' adalah objek modelnya
y_prob_rf = models[name_rf].predict_proba(X_test)[:, 1]

# 2. Hitung False Positive Rate (fpr) dan True Positive Rate (tpr)
fpr, tpr, thresholds = roc_curve(y_test, y_prob_rf)
# Calculate ROC AUC score directly, as 'results' dictionary is not defined
roc_auc = roc_auc_score(y_test, y_prob_rf)

# 3. Plotting (Gunakan plt.subplot(1, 3, 3) jika ingin digabung dengan Grafik A dan B)
plt.figure(figsize=(8, 6))

plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve ({name_rf}, AUC = {roc_auc:.3f})')
plt.plot([0, 1], [0, 1], color='red', lw=2, linestyle='--', label='Random Guess (Akurasi Acak)')

plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate (1 - Spesifisitas)', fontsize=12)
plt.ylabel('True Positive Rate (Recall)', fontsize=12)
plt.title(f'{name_rf} - ROC Curve', fontsize=14)
plt.legend(loc="lower right")
plt.grid(True, linestyle='--', alpha=0.7)

plt.tight_layout()
plt.show()

import pickle

# simpan model
with open("model_air.pkl", "wb") as f:
    pickle.dump(model, f)

# simpan scaler
with open("scaler_air.pkl", "wb") as f:
    pickle.dump(scaler, f)

print("model_air.pkl & scaler_air.pkl berhasil dibuat")

from google.colab import files
files.download("model_air.pkl")
files.download("scaler_air.pkl")

# Commented out IPython magic to ensure Python compatibility.
# %%writefile streamlit_app.py
# import streamlit as st
# import pickle
# import numpy as np
# 
# # 1. Load Model dan Scaler
# with open("model_air.pkl", "rb") as f:
#     model = pickle.load(f)
# with open("scaler_air.pkl", "rb") as f:
#     scaler = pickle.load(f)
# 
# # 2. Judul Web
# st.title("üåä Prediksi Kelayakan Air Minum")
# st.write("Masukkan nilai parameter air di bawah ini untuk mengecek kelayakan.")
# 
# # 3. Input Form
# col1, col2 = st.columns(2)
# with col1:
#     ph = st.number_input("pH", value=7.0)
#     hardness = st.number_input("Hardness", value=150.0)
#     solids = st.number_input("Solids", value=20000.0)
#     chloramines = st.number_input("Chloramines", value=7.0)
#     sulfate = st.number_input("Sulfate", value=300.0)
# 
# with col2:
#     conductivity = st.number_input("Conductivity", value=400.0)
#     organic_carbon = st.number_input("Organic Carbon", value=15.0)
#     trihalomethanes = st.number_input("Trihalomethanes", value=60.0)
#     turbidity = st.number_input("Turbidity", value=4.0)
# 
# # 4. Tombol Prediksi
# if st.button("Cek Kelayakan Air"):
#     # Urutan fitur sesuai training
#     input_data = np.array([[ph, hardness, solids, chloramines, sulfate,
#                             conductivity, organic_carbon, trihalomethanes, turbidity]])
# 
#     # Scaling
#     input_scaled = scaler.transform(input_data)
# 
#     # Prediksi
#     prediction = model.predict(input_scaled)
# 
#     if prediction[0] == 1:
#         st.success("‚úÖ Air ini LAYAK dikonsumsi (Potable)")
#     else:
#         st.error("‚ùå Air ini TIDAK LAYAK dikonsumsi (Not Potable)")

# Commented out IPython magic to ensure Python compatibility.
import os

TOKEN = "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"
USER = "en32345"
REPO = "uasdeeplearning-kelayakan-minum-air"

# Konfigurasi
!git config --global user.email "email@kamu.com"
!git config --global user.name "{USER}"

# Buat Folder & Kirim
# %cd /content/
!mkdir {REPO}
!cp streamlit_app.py model_air.pkl scaler_air.pkl requirements.txt {REPO}/
# %cd {REPO}
!git init
!git add .
!git commit -m "Deploy ke Streamlit"
!git branch -M main
!git remote add origin https://{TOKEN}@github.com/{USER}/{REPO}.git
!git push -u origin main -f

# Commented out IPython magic to ensure Python compatibility.
import os

# GANTI DENGAN DATA KAMU
USER_NAME = "en32345"
TOKEN = "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" # Tempel Token dari Bagian 1 di sini
REPO_NAME = "uasdeeplearning-kelayakan-minum-air" # Nama repo yang kamu buat
EMAIL = "220401079@student.umri.ac.id"

# 1. Setting Identitas
!git config --global user.email "{EMAIL}"
!git config --global user.name "{USER_NAME}"

# 2. Buat folder lokal dan inisialisasi Git
# %cd /content/
!mkdir -p {REPO_NAME} # -p creates directory if it doesn't exist
# %cd {REPO_NAME}
!git init

# --- NEW: Create placeholder files if they don't exist in /content ---
# You need to fill these with actual content later
if not os.path.exists('/content/app.py'):
    with open('/content/app.py', 'w') as f:
        f.write("# Your Streamlit app code goes here\nimport streamlit as st\nst.title('Water Potability Prediction App')")
    print("Created placeholder app.py in /content/")

if not os.path.exists('/content/requirements.txt'):
    with open('/content/requirements.txt', 'w') as f:
        f.write("streamlit\npandas\nnumpy\nscikit-learn\n")
    print("Created placeholder requirements.txt in /content/")
# --- END NEW ---

# 3. Copy file dari Colab ke folder repo
# Sesuaikan nama file yang Anda miliki
!cp /content/app.py ./streamlit_app.py  # Rename ke streamlit_app.py agar rapi
!cp /content/model_air.pkl .
!cp /content/scaler_air.pkl .
!cp /content/requirements.txt .
!cp "{PATH_DATASET}" . # Use the actual path from the find_csv_path function

# 4. Push ke GitHub
repo_url = f"https://{TOKEN}@github.com/{USER_NAME}/{REPO_NAME}.git"

# --- NEW: Remove existing remote origin before adding ---
!git remote remove origin || true
# --- END NEW ---

!git add .
!git commit -m "Initial commit untuk Streamlit" || true # || true to prevent error if no changes
!git branch -M main
!git remote add origin {repo_url}
!git push -u origin main -f

!pip install flask pyngrok
!npm install -g localtunnel